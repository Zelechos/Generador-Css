{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GeneradorCSS.ipynb",
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bb40b076cc7a4dc0a517fadecdb5b272": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8cd849bf864e4623a64c142053351646",
              "IPY_MODEL_8a196453d6e94409a577b95f8af7ba76",
              "IPY_MODEL_41ef0cc556c448fe968591329c0105ab"
            ],
            "layout": "IPY_MODEL_989bbb35b6a447e896f53fde3c99c976"
          }
        },
        "8cd849bf864e4623a64c142053351646": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_972aadbc14184917b646449a83c8a036",
            "placeholder": "​",
            "style": "IPY_MODEL_895be5c6938d49dd87fac6aebe10a4e8",
            "value": "generation_config.json: 100%"
          }
        },
        "8a196453d6e94409a577b95f8af7ba76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23cc22bdca454a69aca4c5f129e1d2ad",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_07b18f665ef14939bbfad4022f20104f",
            "value": 124
          }
        },
        "41ef0cc556c448fe968591329c0105ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2eefb3aaaa9b4ccb8890748aa70c131f",
            "placeholder": "​",
            "style": "IPY_MODEL_8d601d337d3c43608534d5220e582fa3",
            "value": " 124/124 [00:00&lt;00:00, 4.16kB/s]"
          }
        },
        "989bbb35b6a447e896f53fde3c99c976": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "972aadbc14184917b646449a83c8a036": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "895be5c6938d49dd87fac6aebe10a4e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23cc22bdca454a69aca4c5f129e1d2ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07b18f665ef14939bbfad4022f20104f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2eefb3aaaa9b4ccb8890748aa70c131f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d601d337d3c43608534d5220e582fa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zelechos/Generador-Css/blob/main/model/GeneradorCSS_v0.2.1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bN15gvKIX-Ha"
      },
      "source": [
        "# **Proyecto Generador de CSS [v0.2.0]**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VnNOPgW4JHk"
      },
      "source": [
        "# Clonamos nuestro repositorio en donde se encuentra nuestro dataset con este comando"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbRrBcSn4IRF",
        "outputId": "f9f52662-54df-49a5-c2ea-c9d667c99465",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/Zelechos/Generador-Css.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Generador-Css'...\n",
            "remote: Enumerating objects: 708, done.\u001b[K\n",
            "remote: Counting objects: 100% (307/307), done.\u001b[K\n",
            "remote: Compressing objects: 100% (142/142), done.\u001b[K\n",
            "remote: Total 708 (delta 176), reused 275 (delta 151), pack-reused 401\u001b[K\n",
            "Receiving objects: 100% (708/708), 52.79 MiB | 28.53 MiB/s, done.\n",
            "Resolving deltas: 100% (362/362), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3rBPXXFuelK"
      },
      "source": [
        "### en este caso no es necesario ya que tenemos el dataset en github por ende tenemos que trabajar con el dataset que esta en formato json"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Intalamos la libreria trasformers datasets"
      ],
      "metadata": {
        "id": "stwxKXQGnYza"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install transformers datasets"
      ],
      "metadata": {
        "id": "Qm1IwjMenXVO",
        "outputId": "e64e23ed-568c-4bba-9439-2b432c3ef3de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qD_besEJ5uxB"
      },
      "source": [
        "### Cargamos nuestro DATASET\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUUjEn8C5q1p"
      },
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "\n",
        "data_files = {\n",
        "    \"train\": \"/content/Generador-Css/dataset/STYLES.json\",\n",
        "    \"validation\": \"/content/Generador-Css/dataset/TEST.json\",\n",
        "    \"test\": \"/content/Generador-Css/dataset/TEST.json\"\n",
        "}\n",
        "\n",
        "dataset = load_dataset(\"json\", data_files=data_files, field='styles')"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analisamos el Dataset"
      ],
      "metadata": {
        "id": "uB9x7P1CvU-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset.data)"
      ],
      "metadata": {
        "id": "pr_ldsKOvcxd",
        "outputId": "4da6608f-e616-45ca-b0b5-93e286d7f02e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'train': MemoryMappedTable\n",
            "selector: string\n",
            "style: string\n",
            "----\n",
            "selector: [[\"body\",\"div.drop-container\",\"div.drop-container\",\"div.drop-container\",\"div.drop-container\",...,\".image-rotate\",\".image-rotate\",\".image-rotate\",\".image-rotate\",\".image-rotate\"],[\".image-rotate\",\".image-rotate\",\".image-rotate\",\".image-rotate\",\".image-rotate\",...,\".promos\",\".promos\",\".promos\",\".promos\",\".promos\"]]\n",
            "style: [[\"body { overflow:hidden ; background:rgb(25,35,125) } \",\"div.drop-container { position:absolute ; top:0 ; right:0 ; bottom:0 ; left:0 ; margin:auto ; height:200px ; width:200px } \",\"div.drop-container { position:absolute ; top:0 ; right:0 ; bottom:0 ; left:0 ; margin:auto ; height:200px ; width:200px } \",\"div.drop-container { position:absolute ; top:0 ; right:0 ; bottom:0 ; left:0 ; margin:auto ; height:200px ; width:200px } \",\"div.drop-container { position:absolute ; top:0 ; right:0 ; bottom:0 ; left:0 ; margin:auto ; height:200px ; width:200px } \",...,\".image-rotate { overflow:hidden ; margin:8px ; min-width:240px ; max-width:320px ; width:100% ; } .image-rotate img { transition:all 0.3s ; box-sizing:border-box ; max-width:100% ; } .image-rotate:hover img { transform:scale(1.3) rotate(5deg) ; } \",\".image-rotate { overflow:hidden ; margin:8px ; min-width:240px ; max-width:320px ; width:100% ; } .image-rotate img { transition:all 0.3s ; box-sizing:border-box ; max-width:100% ; } .image-rotate:hover img { transform:scale(1.3) rotate(5deg) ; } \",\".image-rotate { overflow:hidden ; margin:8px ; min-width:240px ; max-width:320px ; width:100% ; } .image-rotate img { transition:all 0.3s ; box-sizing:border-box ; max-width:100% ; } .image-rotate:hover img { transform:scale(1.3) rotate(5deg) ; } \",\".image-rotate { overflow:hidden ; margin:8px ; min-width:240px ; max-width:320px ; width:100% ; } .image-rotate img { transition:all 0.3s ; box-sizing:border-box ; max-width:100% ; } .image-rotate:hover img { transform:scale(1.3) rotate(5deg) ; } \",\".image-rotate { overflow:hidden ; margin:8px ; min-width:240px ; max-width:320px ; width:100% ; } .image-rotate img { transition:all 0.3s ; box-sizing:border-box ; max-width:100% ; } .image-rotate:hover img { transform:scale(1.3) rotate(5deg) ; } \"],[\".image-rotate { overflow:hidden ; margin:8px ; min-width:240px ; max-width:320px ; width:100% ; } .image-rotate img { transition:all 0.3s ; box-sizing:border-box ; max-width:100% ; } .image-rotate:hover img { transform:scale(1.3) rotate(5deg) ; } \",\".image-rotate { overflow:hidden ; margin:8px ; min-width:240px ; max-width:320px ; width:100% ; } .image-rotate img { transition:all 0.3s ; box-sizing:border-box ; max-width:100% ; } .image-rotate:hover img { transform:scale(1.3) rotate(5deg) ; } \",\".image-rotate { overflow:hidden ; margin:8px ; min-width:240px ; max-width:320px ; width:100% ; } .image-rotate img { transition:all 0.3s ; box-sizing:border-box ; max-width:100% ; } .image-rotate:hover img { transform:scale(1.3) rotate(5deg) ; } \",\".image-rotate { overflow:hidden ; margin:8px ; min-width:240px ; max-width:320px ; width:100% ; } .image-rotate img { transition:all 0.3s ; box-sizing:border-box ; max-width:100% ; } .image-rotate:hover img { transform:scale(1.3) rotate(5deg) ; } \",\".image-rotate { overflow:hidden ; margin:8px ; min-width:240px ; max-width:320px ; width:100% ; } .image-rotate img { transition:all 0.3s ; box-sizing:border-box ; max-width:100% ; } .image-rotate:hover img { transform:scale(1.3) rotate(5deg) ; } \",...,\".promos { width:800px ; margin:0 auto ; margin-top:50px ; } .promo { width:250px ; background:#10808C ; color:#f9f9f9 ; float:left ; } .deal{ padding:10px 0 0 0 ; } .deal span { display:block ; text-align:center ; } .deal span:first-of-type { font-size:23px ; } .deal span:last-of-type { font-size:13px ; } .promo .price { display:block ; width:250px ; background:#292b2e ; margin:15px 0 10px 0 ; text-align:center ; font-size:23px ; padding:17px 0 17px 0 ; } ul { display:block ; margin:20px 0 10px 0 ; padding:0 ; list-style-type:none ; text-align:center ; color:#999; } li { display:block ; margin:10px 0 0 0 ; } button { border:none ; border-radius:40px ; background:#292b2e ; color:#f9f9f9 ; padding:10px 37px ; margin:10px 0 20px 10px ; } .scale { transform:scale(1.2) ; box-shadow:0 0 4px 1px rgba(20,20,20,.8) ; } .scale button { background:#C51596 ; } .scale .price { color:#D59302 ; } \",\".promos { width:800px ; margin:0 auto ; margin-top:50px ; } .promo { width:250px ; background:#75CA45 ; color:#f9f9f9 ; float:left ; } .deal{ padding:10px 0 0 0 ; } .deal span { display:block ; text-align:center ; } .deal span:first-of-type { font-size:23px ; } .deal span:last-of-type { font-size:13px ; } .promo .price { display:block ; width:250px ; background:#292b2e ; margin:15px 0 10px 0 ; text-align:center ; font-size:23px ; padding:17px 0 17px 0 ; } ul { display:block ; margin:20px 0 10px 0 ; padding:0 ; list-style-type:none ; text-align:center ; color:#999; } li { display:block ; margin:10px 0 0 0 ; } button { border:none ; border-radius:40px ; background:#292b2e ; color:#f9f9f9 ; padding:10px 37px ; margin:10px 0 20px 10px ; } .scale { transform:scale(1.2) ; box-shadow:0 0 4px 1px rgba(20,20,20,.8) ; } .scale button { background:#C66552 ; } .scale .price { color:#B10145 ; } \",\".promos { width:800px ; margin:0 auto ; margin-top:50px ; } .promo { width:250px ; background:#57632C ; color:#f9f9f9 ; float:left ; } .deal{ padding:10px 0 0 0 ; } .deal span { display:block ; text-align:center ; } .deal span:first-of-type { font-size:23px ; } .deal span:last-of-type { font-size:13px ; } .promo .price { display:block ; width:250px ; background:#292b2e ; margin:15px 0 10px 0 ; text-align:center ; font-size:23px ; padding:17px 0 17px 0 ; } ul { display:block ; margin:20px 0 10px 0 ; padding:0 ; list-style-type:none ; text-align:center ; color:#999; } li { display:block ; margin:10px 0 0 0 ; } button { border:none ; border-radius:40px ; background:#292b2e ; color:#f9f9f9 ; padding:10px 37px ; margin:10px 0 20px 10px ; } .scale { transform:scale(1.2) ; box-shadow:0 0 4px 1px rgba(20,20,20,.8) ; } .scale button { background:#3D80A4 ; } .scale .price { color:#5A3870 ; } \",\".promos { width:800px ; margin:0 auto ; margin-top:50px ; } .promo { width:250px ; background:#54B189 ; color:#f9f9f9 ; float:left ; } .deal{ padding:10px 0 0 0 ; } .deal span { display:block ; text-align:center ; } .deal span:first-of-type { font-size:23px ; } .deal span:last-of-type { font-size:13px ; } .promo .price { display:block ; width:250px ; background:#292b2e ; margin:15px 0 10px 0 ; text-align:center ; font-size:23px ; padding:17px 0 17px 0 ; } ul { display:block ; margin:20px 0 10px 0 ; padding:0 ; list-style-type:none ; text-align:center ; color:#999; } li { display:block ; margin:10px 0 0 0 ; } button { border:none ; border-radius:40px ; background:#292b2e ; color:#f9f9f9 ; padding:10px 37px ; margin:10px 0 20px 10px ; } .scale { transform:scale(1.2) ; box-shadow:0 0 4px 1px rgba(20,20,20,.8) ; } .scale button { background:#9C124A ; } .scale .price { color:#A5D013 ; } \",\".promos { width:800px ; margin:0 auto ; margin-top:50px ; } .promo { width:250px ; background:#0D6570 ; color:#f9f9f9 ; float:left ; } .deal{ padding:10px 0 0 0 ; } .deal span { display:block ; text-align:center ; } .deal span:first-of-type { font-size:23px ; } .deal span:last-of-type { font-size:13px ; } .promo .price { display:block ; width:250px ; background:#292b2e ; margin:15px 0 10px 0 ; text-align:center ; font-size:23px ; padding:17px 0 17px 0 ; } ul { display:block ; margin:20px 0 10px 0 ; padding:0 ; list-style-type:none ; text-align:center ; color:#999; } li { display:block ; margin:10px 0 0 0 ; } button { border:none ; border-radius:40px ; background:#292b2e ; color:#f9f9f9 ; padding:10px 37px ; margin:10px 0 20px 10px ; } .scale { transform:scale(1.2) ; box-shadow:0 0 4px 1px rgba(20,20,20,.8) ; } .scale button { background:#035B12 ; } .scale .price { color:#D45146 ; } \"]], 'validation': MemoryMappedTable\n",
            "selector: string\n",
            "style: string\n",
            "----\n",
            "selector: [[\"body\",\"div.drop-container\",\"div.drop-container\",\"div.drop-container\",\"div.drop-container\",...,\".image-rotate\",\".image-rotate\",\".image-rotate\",\".image-rotate\",\".image-rotate\"],[\".image-rotate\",\".image-rotate\",\".image-rotate\",\".image-rotate\",\".image-rotate\",...,\".promos\",\".promos\",\".promos\",\".promos\",\".promos\"]]\n",
            "style: [[\"body { overflow:hidden ; background:rgb(25,35,125) } \",\"div.drop-container { position:absolute ; top:0 ; right:0 ; bottom:0 ; left:0 ; margin:auto ; height:200px ; width:200px } \",\"div.drop-container { position:absolute ; top:0 ; right:0 ; bottom:0 ; left:0 ; margin:auto ; height:200px ; width:200px } \",\"div.drop-container { position:absolute ; top:0 ; right:0 ; bottom:0 ; left:0 ; margin:auto ; height:200px ; width:200px } \",\"div.drop-container { position:absolute ; top:0 ; right:0 ; bottom:0 ; left:0 ; margin:auto ; height:200px ; width:200px } \",...,\".image-rotate { overflow:hidden ; margin:8px ; min-width:240px ; max-width:320px ; width:100% ; } .image-rotate img { transition:all 0.3s ; box-sizing:border-box ; max-width:100% ; } .image-rotate:hover img { transform:scale(1.3) rotate(5deg) ; } \",\".image-rotate { overflow:hidden ; margin:8px ; min-width:240px ; max-width:320px ; width:100% ; } .image-rotate img { transition:all 0.3s ; box-sizing:border-box ; max-width:100% ; } .image-rotate:hover img { transform:scale(1.3) rotate(5deg) ; } \",\".image-rotate { overflow:hidden ; margin:8px ; min-width:240px ; max-width:320px ; width:100% ; } .image-rotate img { transition:all 0.3s ; box-sizing:border-box ; max-width:100% ; } .image-rotate:hover img { transform:scale(1.3) rotate(5deg) ; } \",\".image-rotate { overflow:hidden ; margin:8px ; min-width:240px ; max-width:320px ; width:100% ; } .image-rotate img { transition:all 0.3s ; box-sizing:border-box ; max-width:100% ; } .image-rotate:hover img { transform:scale(1.3) rotate(5deg) ; } \",\".image-rotate { overflow:hidden ; margin:8px ; min-width:240px ; max-width:320px ; width:100% ; } .image-rotate img { transition:all 0.3s ; box-sizing:border-box ; max-width:100% ; } .image-rotate:hover img { transform:scale(1.3) rotate(5deg) ; } \"],[\".image-rotate { overflow:hidden ; margin:8px ; min-width:240px ; max-width:320px ; width:100% ; } .image-rotate img { transition:all 0.3s ; box-sizing:border-box ; max-width:100% ; } .image-rotate:hover img { transform:scale(1.3) rotate(5deg) ; } \",\".image-rotate { overflow:hidden ; margin:8px ; min-width:240px ; max-width:320px ; width:100% ; } .image-rotate img { transition:all 0.3s ; box-sizing:border-box ; max-width:100% ; } .image-rotate:hover img { transform:scale(1.3) rotate(5deg) ; } \",\".image-rotate { overflow:hidden ; margin:8px ; min-width:240px ; max-width:320px ; width:100% ; } .image-rotate img { transition:all 0.3s ; box-sizing:border-box ; max-width:100% ; } .image-rotate:hover img { transform:scale(1.3) rotate(5deg) ; } \",\".image-rotate { overflow:hidden ; margin:8px ; min-width:240px ; max-width:320px ; width:100% ; } .image-rotate img { transition:all 0.3s ; box-sizing:border-box ; max-width:100% ; } .image-rotate:hover img { transform:scale(1.3) rotate(5deg) ; } \",\".image-rotate { overflow:hidden ; margin:8px ; min-width:240px ; max-width:320px ; width:100% ; } .image-rotate img { transition:all 0.3s ; box-sizing:border-box ; max-width:100% ; } .image-rotate:hover img { transform:scale(1.3) rotate(5deg) ; } \",...,\".promos { width:800px ; margin:0 auto ; margin-top:50px ; } .promo { width:250px ; background:#10808C ; color:#f9f9f9 ; float:left ; } .deal{ padding:10px 0 0 0 ; } .deal span { display:block ; text-align:center ; } .deal span:first-of-type { font-size:23px ; } .deal span:last-of-type { font-size:13px ; } .promo .price { display:block ; width:250px ; background:#292b2e ; margin:15px 0 10px 0 ; text-align:center ; font-size:23px ; padding:17px 0 17px 0 ; } ul { display:block ; margin:20px 0 10px 0 ; padding:0 ; list-style-type:none ; text-align:center ; color:#999; } li { display:block ; margin:10px 0 0 0 ; } button { border:none ; border-radius:40px ; background:#292b2e ; color:#f9f9f9 ; padding:10px 37px ; margin:10px 0 20px 10px ; } .scale { transform:scale(1.2) ; box-shadow:0 0 4px 1px rgba(20,20,20,.8) ; } .scale button { background:#C51596 ; } .scale .price { color:#D59302 ; } \",\".promos { width:800px ; margin:0 auto ; margin-top:50px ; } .promo { width:250px ; background:#75CA45 ; color:#f9f9f9 ; float:left ; } .deal{ padding:10px 0 0 0 ; } .deal span { display:block ; text-align:center ; } .deal span:first-of-type { font-size:23px ; } .deal span:last-of-type { font-size:13px ; } .promo .price { display:block ; width:250px ; background:#292b2e ; margin:15px 0 10px 0 ; text-align:center ; font-size:23px ; padding:17px 0 17px 0 ; } ul { display:block ; margin:20px 0 10px 0 ; padding:0 ; list-style-type:none ; text-align:center ; color:#999; } li { display:block ; margin:10px 0 0 0 ; } button { border:none ; border-radius:40px ; background:#292b2e ; color:#f9f9f9 ; padding:10px 37px ; margin:10px 0 20px 10px ; } .scale { transform:scale(1.2) ; box-shadow:0 0 4px 1px rgba(20,20,20,.8) ; } .scale button { background:#C66552 ; } .scale .price { color:#B10145 ; } \",\".promos { width:800px ; margin:0 auto ; margin-top:50px ; } .promo { width:250px ; background:#57632C ; color:#f9f9f9 ; float:left ; } .deal{ padding:10px 0 0 0 ; } .deal span { display:block ; text-align:center ; } .deal span:first-of-type { font-size:23px ; } .deal span:last-of-type { font-size:13px ; } .promo .price { display:block ; width:250px ; background:#292b2e ; margin:15px 0 10px 0 ; text-align:center ; font-size:23px ; padding:17px 0 17px 0 ; } ul { display:block ; margin:20px 0 10px 0 ; padding:0 ; list-style-type:none ; text-align:center ; color:#999; } li { display:block ; margin:10px 0 0 0 ; } button { border:none ; border-radius:40px ; background:#292b2e ; color:#f9f9f9 ; padding:10px 37px ; margin:10px 0 20px 10px ; } .scale { transform:scale(1.2) ; box-shadow:0 0 4px 1px rgba(20,20,20,.8) ; } .scale button { background:#3D80A4 ; } .scale .price { color:#5A3870 ; } \",\".promos { width:800px ; margin:0 auto ; margin-top:50px ; } .promo { width:250px ; background:#54B189 ; color:#f9f9f9 ; float:left ; } .deal{ padding:10px 0 0 0 ; } .deal span { display:block ; text-align:center ; } .deal span:first-of-type { font-size:23px ; } .deal span:last-of-type { font-size:13px ; } .promo .price { display:block ; width:250px ; background:#292b2e ; margin:15px 0 10px 0 ; text-align:center ; font-size:23px ; padding:17px 0 17px 0 ; } ul { display:block ; margin:20px 0 10px 0 ; padding:0 ; list-style-type:none ; text-align:center ; color:#999; } li { display:block ; margin:10px 0 0 0 ; } button { border:none ; border-radius:40px ; background:#292b2e ; color:#f9f9f9 ; padding:10px 37px ; margin:10px 0 20px 10px ; } .scale { transform:scale(1.2) ; box-shadow:0 0 4px 1px rgba(20,20,20,.8) ; } .scale button { background:#9C124A ; } .scale .price { color:#A5D013 ; } \",\".promos { width:800px ; margin:0 auto ; margin-top:50px ; } .promo { width:250px ; background:#0D6570 ; color:#f9f9f9 ; float:left ; } .deal{ padding:10px 0 0 0 ; } .deal span { display:block ; text-align:center ; } .deal span:first-of-type { font-size:23px ; } .deal span:last-of-type { font-size:13px ; } .promo .price { display:block ; width:250px ; background:#292b2e ; margin:15px 0 10px 0 ; text-align:center ; font-size:23px ; padding:17px 0 17px 0 ; } ul { display:block ; margin:20px 0 10px 0 ; padding:0 ; list-style-type:none ; text-align:center ; color:#999; } li { display:block ; margin:10px 0 0 0 ; } button { border:none ; border-radius:40px ; background:#292b2e ; color:#f9f9f9 ; padding:10px 37px ; margin:10px 0 20px 10px ; } .scale { transform:scale(1.2) ; box-shadow:0 0 4px 1px rgba(20,20,20,.8) ; } .scale button { background:#035B12 ; } .scale .price { color:#D45146 ; } \"]], 'test': MemoryMappedTable\n",
            "selector: string\n",
            "style: string\n",
            "----\n",
            "selector: [[\"body\",\"div.drop-container\",\"div.drop-container\",\"div.drop-container\",\"div.drop-container\",...,\".image-rotate\",\".image-rotate\",\".image-rotate\",\".image-rotate\",\".image-rotate\"],[\".image-rotate\",\".image-rotate\",\".image-rotate\",\".image-rotate\",\".image-rotate\",...,\".promos\",\".promos\",\".promos\",\".promos\",\".promos\"]]\n",
            "style: [[\"body { overflow:hidden ; background:rgb(25,35,125) } \",\"div.drop-container { position:absolute ; top:0 ; right:0 ; bottom:0 ; left:0 ; margin:auto ; height:200px ; width:200px } \",\"div.drop-container { position:absolute ; top:0 ; right:0 ; bottom:0 ; left:0 ; margin:auto ; height:200px ; width:200px } \",\"div.drop-container { position:absolute ; top:0 ; right:0 ; bottom:0 ; left:0 ; margin:auto ; height:200px ; width:200px } \",\"div.drop-container { position:absolute ; top:0 ; right:0 ; bottom:0 ; left:0 ; margin:auto ; height:200px ; width:200px } \",...,\".image-rotate { overflow:hidden ; margin:8px ; min-width:240px ; max-width:320px ; width:100% ; } .image-rotate img { transition:all 0.3s ; box-sizing:border-box ; max-width:100% ; } .image-rotate:hover img { transform:scale(1.3) rotate(5deg) ; } \",\".image-rotate { overflow:hidden ; margin:8px ; min-width:240px ; max-width:320px ; width:100% ; } .image-rotate img { transition:all 0.3s ; box-sizing:border-box ; max-width:100% ; } .image-rotate:hover img { transform:scale(1.3) rotate(5deg) ; } \",\".image-rotate { overflow:hidden ; margin:8px ; min-width:240px ; max-width:320px ; width:100% ; } .image-rotate img { transition:all 0.3s ; box-sizing:border-box ; max-width:100% ; } .image-rotate:hover img { transform:scale(1.3) rotate(5deg) ; } \",\".image-rotate { overflow:hidden ; margin:8px ; min-width:240px ; max-width:320px ; width:100% ; } .image-rotate img { transition:all 0.3s ; box-sizing:border-box ; max-width:100% ; } .image-rotate:hover img { transform:scale(1.3) rotate(5deg) ; } \",\".image-rotate { overflow:hidden ; margin:8px ; min-width:240px ; max-width:320px ; width:100% ; } .image-rotate img { transition:all 0.3s ; box-sizing:border-box ; max-width:100% ; } .image-rotate:hover img { transform:scale(1.3) rotate(5deg) ; } \"],[\".image-rotate { overflow:hidden ; margin:8px ; min-width:240px ; max-width:320px ; width:100% ; } .image-rotate img { transition:all 0.3s ; box-sizing:border-box ; max-width:100% ; } .image-rotate:hover img { transform:scale(1.3) rotate(5deg) ; } \",\".image-rotate { overflow:hidden ; margin:8px ; min-width:240px ; max-width:320px ; width:100% ; } .image-rotate img { transition:all 0.3s ; box-sizing:border-box ; max-width:100% ; } .image-rotate:hover img { transform:scale(1.3) rotate(5deg) ; } \",\".image-rotate { overflow:hidden ; margin:8px ; min-width:240px ; max-width:320px ; width:100% ; } .image-rotate img { transition:all 0.3s ; box-sizing:border-box ; max-width:100% ; } .image-rotate:hover img { transform:scale(1.3) rotate(5deg) ; } \",\".image-rotate { overflow:hidden ; margin:8px ; min-width:240px ; max-width:320px ; width:100% ; } .image-rotate img { transition:all 0.3s ; box-sizing:border-box ; max-width:100% ; } .image-rotate:hover img { transform:scale(1.3) rotate(5deg) ; } \",\".image-rotate { overflow:hidden ; margin:8px ; min-width:240px ; max-width:320px ; width:100% ; } .image-rotate img { transition:all 0.3s ; box-sizing:border-box ; max-width:100% ; } .image-rotate:hover img { transform:scale(1.3) rotate(5deg) ; } \",...,\".promos { width:800px ; margin:0 auto ; margin-top:50px ; } .promo { width:250px ; background:#10808C ; color:#f9f9f9 ; float:left ; } .deal{ padding:10px 0 0 0 ; } .deal span { display:block ; text-align:center ; } .deal span:first-of-type { font-size:23px ; } .deal span:last-of-type { font-size:13px ; } .promo .price { display:block ; width:250px ; background:#292b2e ; margin:15px 0 10px 0 ; text-align:center ; font-size:23px ; padding:17px 0 17px 0 ; } ul { display:block ; margin:20px 0 10px 0 ; padding:0 ; list-style-type:none ; text-align:center ; color:#999; } li { display:block ; margin:10px 0 0 0 ; } button { border:none ; border-radius:40px ; background:#292b2e ; color:#f9f9f9 ; padding:10px 37px ; margin:10px 0 20px 10px ; } .scale { transform:scale(1.2) ; box-shadow:0 0 4px 1px rgba(20,20,20,.8) ; } .scale button { background:#C51596 ; } .scale .price { color:#D59302 ; } \",\".promos { width:800px ; margin:0 auto ; margin-top:50px ; } .promo { width:250px ; background:#75CA45 ; color:#f9f9f9 ; float:left ; } .deal{ padding:10px 0 0 0 ; } .deal span { display:block ; text-align:center ; } .deal span:first-of-type { font-size:23px ; } .deal span:last-of-type { font-size:13px ; } .promo .price { display:block ; width:250px ; background:#292b2e ; margin:15px 0 10px 0 ; text-align:center ; font-size:23px ; padding:17px 0 17px 0 ; } ul { display:block ; margin:20px 0 10px 0 ; padding:0 ; list-style-type:none ; text-align:center ; color:#999; } li { display:block ; margin:10px 0 0 0 ; } button { border:none ; border-radius:40px ; background:#292b2e ; color:#f9f9f9 ; padding:10px 37px ; margin:10px 0 20px 10px ; } .scale { transform:scale(1.2) ; box-shadow:0 0 4px 1px rgba(20,20,20,.8) ; } .scale button { background:#C66552 ; } .scale .price { color:#B10145 ; } \",\".promos { width:800px ; margin:0 auto ; margin-top:50px ; } .promo { width:250px ; background:#57632C ; color:#f9f9f9 ; float:left ; } .deal{ padding:10px 0 0 0 ; } .deal span { display:block ; text-align:center ; } .deal span:first-of-type { font-size:23px ; } .deal span:last-of-type { font-size:13px ; } .promo .price { display:block ; width:250px ; background:#292b2e ; margin:15px 0 10px 0 ; text-align:center ; font-size:23px ; padding:17px 0 17px 0 ; } ul { display:block ; margin:20px 0 10px 0 ; padding:0 ; list-style-type:none ; text-align:center ; color:#999; } li { display:block ; margin:10px 0 0 0 ; } button { border:none ; border-radius:40px ; background:#292b2e ; color:#f9f9f9 ; padding:10px 37px ; margin:10px 0 20px 10px ; } .scale { transform:scale(1.2) ; box-shadow:0 0 4px 1px rgba(20,20,20,.8) ; } .scale button { background:#3D80A4 ; } .scale .price { color:#5A3870 ; } \",\".promos { width:800px ; margin:0 auto ; margin-top:50px ; } .promo { width:250px ; background:#54B189 ; color:#f9f9f9 ; float:left ; } .deal{ padding:10px 0 0 0 ; } .deal span { display:block ; text-align:center ; } .deal span:first-of-type { font-size:23px ; } .deal span:last-of-type { font-size:13px ; } .promo .price { display:block ; width:250px ; background:#292b2e ; margin:15px 0 10px 0 ; text-align:center ; font-size:23px ; padding:17px 0 17px 0 ; } ul { display:block ; margin:20px 0 10px 0 ; padding:0 ; list-style-type:none ; text-align:center ; color:#999; } li { display:block ; margin:10px 0 0 0 ; } button { border:none ; border-radius:40px ; background:#292b2e ; color:#f9f9f9 ; padding:10px 37px ; margin:10px 0 20px 10px ; } .scale { transform:scale(1.2) ; box-shadow:0 0 4px 1px rgba(20,20,20,.8) ; } .scale button { background:#9C124A ; } .scale .price { color:#A5D013 ; } \",\".promos { width:800px ; margin:0 auto ; margin-top:50px ; } .promo { width:250px ; background:#0D6570 ; color:#f9f9f9 ; float:left ; } .deal{ padding:10px 0 0 0 ; } .deal span { display:block ; text-align:center ; } .deal span:first-of-type { font-size:23px ; } .deal span:last-of-type { font-size:13px ; } .promo .price { display:block ; width:250px ; background:#292b2e ; margin:15px 0 10px 0 ; text-align:center ; font-size:23px ; padding:17px 0 17px 0 ; } ul { display:block ; margin:20px 0 10px 0 ; padding:0 ; list-style-type:none ; text-align:center ; color:#999; } li { display:block ; margin:10px 0 0 0 ; } button { border:none ; border-radius:40px ; background:#292b2e ; color:#f9f9f9 ; padding:10px 37px ; margin:10px 0 20px 10px ; } .scale { transform:scale(1.2) ; box-shadow:0 0 4px 1px rgba(20,20,20,.8) ; } .scale button { background:#035B12 ; } .scale .price { color:#D45146 ; } \"]]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyLQIJ6A6Qom"
      },
      "source": [
        "### Cargando nuestro modelo Pre-entrenado GPT-2 XL"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer, TFGPT2Model\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2-xl')\n",
        "model = TFGPT2Model.from_pretrained('gpt2-xl')\n",
        "\n",
        "text = \"Replace me by any text you'd like.\"\n",
        "encoded_input = tokenizer(text, return_tensors='tf')\n",
        "output = model(encoded_input)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "HVrKH8uJnPAE",
        "outputId": "c81a90cb-f41c-4e16-cbaa-7566a8ac554f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "{{function_node __wrapped__StatelessTruncatedNormalV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[50257,1600] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:StatelessTruncatedNormalV2] name: ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-8625e74cbbba>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPT2Tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gpt2-xl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTFGPT2Model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gpt2-xl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Replace me by any text you'd like.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2892\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_in_name_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# build the network with dummy inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2893\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2894\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_in_name_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# build the network with dummy inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2896\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msafetensors_from_pt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\u001b[0m in \u001b[0;36mbuild_in_name_scope\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild_in_name_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/gpt2/modeling_tf_gpt2.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    834\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transformer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 836\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/gpt2/modeling_tf_gpt2.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    574\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wte\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwte\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwte\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wpe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/utils/tf_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(instance, input_shape)\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m             \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_tuples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m         \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m         \u001b[0;31m# Return shapes from `fn` as TensorShapes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/layers/core/embedding.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_type_conversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         self.embeddings = self.add_weight(\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings_initializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0mgetter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m         variable = self._add_variable_with_custom_getter(\n\u001b[0m\u001b[1;32m    700\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/trackable/base.py\u001b[0m in \u001b[0;36m_add_variable_with_custom_getter\u001b[0;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;31m# \"best effort\" to set the initializer with the highest restore UID.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0minitializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint_initializer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m     new_variable = getter(\n\u001b[0m\u001b[1;32m    493\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/base_layer_utils.py\u001b[0m in \u001b[0;36mmake_variable\u001b[0;34m(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner, layout, experimental_enable_variable_lifting)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;31m# However, this breaks legacy (Estimator) checkpoints because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;31m# it changes variable names. Remove this when V1 is fully deprecated.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         return tf1.Variable(\n\u001b[0m\u001b[1;32m    138\u001b[0m             \u001b[0minitial_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/initializers/initializers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, shape, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0mnonce\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             )\n\u001b[0;32m--> 525\u001b[0;31m         return self._random_generator.truncated_normal(\n\u001b[0m\u001b[1;32m    526\u001b[0m             \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstddev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnonce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/backend.py\u001b[0m in \u001b[0;36mtruncated_normal\u001b[0;34m(self, shape, mean, stddev, dtype, nonce)\u001b[0m\n\u001b[1;32m   2142\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnonce\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2143\u001b[0m                 \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateless_fold_in\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnonce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2144\u001b[0;31m             return tf.random.stateless_truncated_normal(\n\u001b[0m\u001b[1;32m   2145\u001b[0m                 \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstddev\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstddev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2146\u001b[0m             )\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: {{function_node __wrapped__StatelessTruncatedNormalV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[50257,1600] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:StatelessTruncatedNormalV2] name: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline, set_seed\n",
        "generator = pipeline('text-generation', model='gpt2-xl')\n",
        "set_seed(42)\n",
        "generator(\"The man worked as a\", max_length=10, num_return_sequences=5)\n",
        "\n",
        "set_seed(42)\n",
        "generator(\"The woman worked as a\", max_length=10, num_return_sequences=5)\n"
      ],
      "metadata": {
        "id": "gOYaCK7WpgRK",
        "outputId": "af38775c-d59b-4b4a-a736-47468f4c0c20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208,
          "referenced_widgets": [
            "bb40b076cc7a4dc0a517fadecdb5b272",
            "8cd849bf864e4623a64c142053351646",
            "8a196453d6e94409a577b95f8af7ba76",
            "41ef0cc556c448fe968591329c0105ab",
            "989bbb35b6a447e896f53fde3c99c976",
            "972aadbc14184917b646449a83c8a036",
            "895be5c6938d49dd87fac6aebe10a4e8",
            "23cc22bdca454a69aca4c5f129e1d2ad",
            "07b18f665ef14939bbfad4022f20104f",
            "2eefb3aaaa9b4ccb8890748aa70c131f",
            "8d601d337d3c43608534d5220e582fa3"
          ]
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bb40b076cc7a4dc0a517fadecdb5b272"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'The woman worked as a supervisor for the company.'},\n",
              " {'generated_text': \"The woman worked as a volunteer at the Children's\"},\n",
              " {'generated_text': 'The woman worked as a waitress at a New Jersey'},\n",
              " {'generated_text': 'The woman worked as a lab technician but quit to'},\n",
              " {'generated_text': 'The woman worked as a prostitute, according to reports'}]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analisis del Modelo GTP-2 XL"
      ],
      "metadata": {
        "id": "8FiPbKWwsI6B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experimento 001**\n",
        "- Cambiamos el parametro max_length a 50\n",
        "que dadas las observaciones define la longitud de palabras maximas que puede tener la sentencia a generar\n",
        "- El parametro num_return_sequences = 1"
      ],
      "metadata": {
        "id": "KOiVgLwepywm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(42)\n",
        "generator(\"Alan Turing was a\", max_length=50, num_return_sequences=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d17aS1znpyUR",
        "outputId": "88961de7-6ef4-4468-f904-3db91eea4ca9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'Alan Turing was a brilliant mathematician, but you can\\'t beat a human being in a chess match with any of the chess engines out there. So for computer chess, he said, \"You are only ever going to beat a human being in a game'}]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experimento 002**\n",
        "- Cambiamos el parametro max_length a 2\n",
        "que dadas las observaciones define la longitud de palabras maximas que puede tener la sentencia a generar\n",
        "- Tambien Cambiamos el parametro num_return_sequences a 3\n",
        "que dadas las observaciones es la cantidad de sentencias que genera el modelo considerando la longitud de palabras antes definida\n",
        "\n",
        "*Se observo que al poner el parametro de max_length = 2 presenta un error por la longitud del input*"
      ],
      "metadata": {
        "id": "bJkFYaKDsbA6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator(\"a Transformer in AI is\", max_length=2, num_return_sequences=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "cecG0sfask2O",
        "outputId": "a45b685e-32e0-4eae-e6e8-184e777d905b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Input length of input_ids is 2, but `max_length` is set to 2. This can lead to unexpected behavior. You should consider increasing `max_length` or, better yet, setting `max_new_tokens`.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-baa8893b7f08>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"a Transformer in AI is\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_return_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text_generation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    239\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     def preprocess(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1194\u001b[0m             )\n\u001b[1;32m   1195\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1196\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_multi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mrun_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m         \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpreprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1203\u001b[0;31m         \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1204\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0minference_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m                     \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1102\u001b[0;31m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text_generation.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0;31m# BS x SL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0mgenerated_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mgenerate_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m         \u001b[0mout_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerated_sequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1464\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_cls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_cache_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgeneration_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1466\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_generated_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeneration_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_default_max_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1468\u001b[0m         \u001b[0;31m# 7. determine generation mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_validate_generated_length\u001b[0;34m(self, generation_config, input_ids_length, has_default_max_length)\u001b[0m\n\u001b[1;32m   1184\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minput_ids_length\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mgeneration_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0minput_ids_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"decoder_input_ids\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_encoder_decoder\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1187\u001b[0m                 \u001b[0;34mf\"Input length of {input_ids_string} is {input_ids_length}, but `max_length` is set to\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m                 \u001b[0;34mf\" {generation_config.max_length}. This can lead to unexpected behavior. You should consider\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input length of input_ids is 2, but `max_length` is set to 2. This can lead to unexpected behavior. You should consider increasing `max_length` or, better yet, setting `max_new_tokens`."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experimento 003**\n",
        "- Cambiamos el parametro max_length a 7\n",
        "que dadas las observaciones define la longitud de palabras maximas que puede tener la sentencia a generar incluyendo el input\n",
        "- Tambien Cambiamos el parametro num_return_sequences a 3\n",
        "que dadas las observaciones es la cantidad de sentencias que genera el modelo considerando la longitud de palabras antes definida\n",
        "\n",
        "Se observo que con el parametro max_length = 2 hay una error dado que el parametro max_length debe superar en longitud de input_ids es N entonces el parametro max_length siempre tiene que ser almenos N + 1 o mayor que."
      ],
      "metadata": {
        "id": "-HkP3zXJtowl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator(\"a Transformer in AI is\", max_length=10, num_return_sequences=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hFbIJPotNMW",
        "outputId": "896ae3c8-a12b-42cc-f9bc-9c204f69e181"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'a Transformer in AI is the same as that'},\n",
              " {'generated_text': 'a Transformer in AI is a powerful engine ('},\n",
              " {'generated_text': 'a Transformer in AI is more than worth it'}]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experimento 004**\n",
        "- Definimos el parametro de la semilla en 30 para observar que sucede\n"
      ],
      "metadata": {
        "id": "TPcGiZMDXumw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(30)\n",
        "generator(\"a Artificial Neural Network is\", max_length=15, num_return_sequences=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVNceQDdX65J",
        "outputId": "276a4911-e45e-4a69-8e75-37f9b7e6459e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'a Artificial Neural Network is a machine learning algorithm that combines a number of techniques'},\n",
              " {'generated_text': 'a Artificial Neural Network is a program capable of learning and recognizing symbols and patterns'},\n",
              " {'generated_text': 'a Artificial Neural Network is trained on a large number of digitized music examples'}]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aplicar Transfer Learning de GPT-2 XL a GeneradorCSS"
      ],
      "metadata": {
        "id": "K4VtBh6FY4FR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer, TFGPT2Model\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2-xl')\n",
        "model = TFGPT2Model.from_pretrained('gpt2-xl')\n",
        "\n",
        "# Selecciona un token existente como token de relleno\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# text = \"Replace me by any text you'd like.\"\n",
        "# encoded_input = tokenizer(text, return_tensors='tf')\n",
        "# output = model(encoded_input)"
      ],
      "metadata": {
        "id": "CTQcPe0rZIuu",
        "outputId": "fc67f84f-a597-4eff-ed56-789356a94dc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InternalError",
          "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-6d5c4e61d830>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPT2Tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gpt2-xl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTFGPT2Model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gpt2-xl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Selecciona un token existente como token de relleno\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2901\u001b[0m                 \u001b[0;31m# We load in TF format here because PT weights often need to be transposed, and this is much\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2902\u001b[0m                 \u001b[0;31m# faster on GPU. Loading as numpy and transposing on CPU adds several seconds to load times.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2903\u001b[0;31m                 return load_pytorch_state_dict_in_tf2_model(\n\u001b[0m\u001b[1;32m   2904\u001b[0m                     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                     \u001b[0msafetensors_archive\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_pytorch_utils.py\u001b[0m in \u001b[0;36mload_pytorch_state_dict_in_tf2_model\u001b[0;34m(tf_model, pt_state_dict, tf_inputs, allow_missing_keys, output_loading_info, _prefix, tf_to_pt_weight_rename, ignore_mismatched_sizes)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0mstate_dict_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_keys_to_pt_keys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_safetensor_archive\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpt_state_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpt_state_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate_dict_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    101\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seleccionando un token de relleno existente"
      ],
      "metadata": {
        "id": "vs8R8hBs1RcP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecciona un token existente como token de relleno\n",
        "tokenizer.pad_token = tokenizer.eos_token\n"
      ],
      "metadata": {
        "id": "g1S9XXMF1X5t"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creamos la funcionr para tokenizar el dataset"
      ],
      "metadata": {
        "id": "lXj9a0_slgZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(examples):\n",
        "  return tokenizer(examples[\"style\"], padding=\"max_length\", truncation=True)"
      ],
      "metadata": {
        "id": "x4FtN7TeloBW"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenizamos nuestro dataset"
      ],
      "metadata": {
        "id": "5CmoPlPamSRP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
        "print(tokenized_datasets['train'])"
      ],
      "metadata": {
        "id": "Wtq0L6jomXYl",
        "outputId": "e137df61-b502-4e4e-d95d-4d279962cb64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['selector', 'style', 'input_ids', 'attention_mask'],\n",
            "    num_rows: 1337\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si lo desea, puede crear un subconjunto más pequeño del conjunto de datos completo para realizar ajustes y reducir el tiempo necesario:"
      ],
      "metadata": {
        "id": "00yRhptl2Bjz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n",
        "small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))"
      ],
      "metadata": {
        "id": "HLhHa3Gu1_xi",
        "outputId": "9a3e3b79-0275-4d7a-9f68-3d234ff9f434",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['selector', 'style', 'input_ids', 'attention_mask'],\n",
            "    num_rows: 1000\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "labels = np.array(tokenized_datasets['train']['selector'])  # Label is already an array of 0 and 1"
      ],
      "metadata": {
        "id": "BYTy0IzM3ci5"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModelForSequenceClassification\n",
        "from tensorflow.keras.optimizers import Adam\n"
      ],
      "metadata": {
        "id": "fD9rgI6S4T6t"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Lower learning rates are often better for fine-tuning transformers\n",
        "model.compile(optimizer=Adam(3e-5), loss='sparse_categorical_crossentropy')\n",
        "\n",
        "model.fit(tokenized_datasets['train'], labels)"
      ],
      "metadata": {
        "id": "K3xaodCe3O1Q",
        "outputId": "949c3cd8-9c7c-4d59-847f-8e71c536afed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Could not interpret optimizer identifier: <keras.src.optimizers.adam.Adam object at 0x7ec505f6a830>",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-b7bdf0f0b746>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Lower learning rates are often better for fine-tuning transformers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, weighted_metrics, run_eagerly, steps_per_execution, **kwargs)\u001b[0m\n\u001b[1;32m   1493\u001b[0m         \u001b[0;31m# This argument got renamed, we need to support both versions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1494\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"steps_per_execution\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparent_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1495\u001b[0;31m             super().compile(\n\u001b[0m\u001b[1;32m   1496\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/optimizers/__init__.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(identifier, **kwargs)\u001b[0m\n\u001b[1;32m    332\u001b[0m         )\n\u001b[1;32m    333\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    335\u001b[0m             \u001b[0;34mf\"Could not interpret optimizer identifier: {identifier}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         )\n",
            "\u001b[0;31mValueError\u001b[0m: Could not interpret optimizer identifier: <keras.src.optimizers.adam.Adam object at 0x7ec505f6a830>"
          ]
        }
      ]
    }
  ]
}