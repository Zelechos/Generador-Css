{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GeneradorCSS.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zelechos/Generador-Css/blob/main/GeneradorCSS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bN15gvKIX-Ha"
      },
      "source": [
        "# **Proyecto Generador de CSS [v0.0.8]**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VnNOPgW4JHk"
      },
      "source": [
        "# Clonamos nuestro repositorio en donde se encuentra nuestro dataset con este comando"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbRrBcSn4IRF",
        "outputId": "ce8e2e4a-d18e-4664-b7b0-9f966b07e794",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/Zelechos/Generador-Css.git"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Generador-Css' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3rBPXXFuelK"
      },
      "source": [
        "### en este caso no es necesario ya que tenemos el dataset en github por ende tenemos que trabajar con el dataset que esta en formato json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qD_besEJ5uxB"
      },
      "source": [
        "### Accedemos a los datos del dataset TEST.json\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUUjEn8C5q1p",
        "outputId": "9b1ef3d8-58c6-4d3a-f055-8b8fa5d0ff89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import json\n",
        "\n",
        "with open('/content/Generador-Css/dataset/TEST.json') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "#accedemos a la los datos\n",
        "data_styles = data[\"styles\"]\n",
        "print(data_styles[0])\n",
        "\n",
        "\n",
        "#accediendo a los estilos\n",
        "styles = data_styles[0][\"style\"]\n",
        "print(\"\\nstyles access => \",styles)\n",
        "\n",
        "\n",
        "#accediendo a los selectores\n",
        "selector = data_styles[0][\"selector\"]\n",
        "print(\"\\nselector access => \",selector)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'style': 'body{overflow:hidden;background:rgb(25,35,125)}', 'selector': 'body'}\n",
            "\n",
            "styles access =>  body{overflow:hidden;background:rgb(25,35,125)}\n",
            "\n",
            "selector access =>  body\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyLQIJ6A6Qom"
      },
      "source": [
        "### Creamos un array para poder mandar los datos y luego tranformarlos en numeros"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzfDVXgs6Xu2",
        "outputId": "0cc11b6d-e1c0-4fc3-b4e1-5abbe09c2e30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data_css = []\n",
        "styles = []\n",
        "selectors = []\n",
        "for data in data_styles:\n",
        "  selectors.append(data[\"selector\"])\n",
        "  styles.append(data[\"style\"])\n",
        " \n",
        "# print(selectors)\n",
        "# print(styles)\n",
        "data_css.append(selectors)\n",
        "data_css.append(styles)\n",
        "print(data_css[0])\n",
        "print(data_css[1])\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['body', 'div.drop-container', 'div.drop', 'h1', '@font-face', 'body', '.logo', '.switch-left', '.pad-left', '.switch-right', '.pad-right', '.line', '.text', '.text', '.text', '.reload', '.logo', 'html,body', 'body', '*', '*', '*', '.css_lab', '.witch', 'body', 'body img', 'img', 'body h1', 'h1', 'body a', 'a', '@keyframes glow', 'from', 'to', 'body', 'h1', 'ul', 'li', 'li:hover span', 'li.invisible', 'li.animate', 'span', 'span:before', 'html', 'body', 'header', 'article', 'h3,section', 'h3', 'section', 'h3:before', 'h3:before,section:before', 'section:before', 'h3', 'section', 'h3:before', 'section:before', 'p', 'a', 'body,html', 'body', 'html', 'div.codepen', 'div', '.codepen', '*', 'body', 'aside.context', '.context', 'aside', 'a', 'a:hover', 'footer', 'footer a', 'a']\n",
            "['body{overflow:hidden;background:rgb(25,35,125)}', 'div.drop-container{position:absolute;top:0;right:0;bottom:0;left:0;margin:auto;height:200px;width:200px}', 'div.drop{position:absolute;top:-25%;width:100%;height:100%;border-radius:100% 5% 100% 100%;-webkit-transform:rotate(-45deg);transform:rotate(-45deg);margin:0;background:deepskyblue;-webkit-animation:drip 4s forwards;animation:drip 4s forwards}', 'h1{color:#fff;position:absolute;font-size:2.5em;height:1em;top:0;left:0;right:0;bottom:0;z-index:2;margin:auto;text-align:center;opacity:0;-webkit-animation:appear 2s 2.5s forwards;animation:appear 2s 2.5s forwards}', '@font-face {font-family: logofont;src: url(https://s3-us-west-2.amazonaws.com/s.cdpn.io/531144/couture-bld.otf);}', 'body {margin: 0px;background: #EF5350;}', '.logo {transform: scale(0.7);margin-top: 45px;}', '.switch-left{position:fixed;background:transparent;width:130px;height:380px;border-radius:100px 5px 5px 100px;border:35px solid #fff;transform:translate(calc(50vw - 217px),calc(50vh - 225px));animation:switch-left-animation 1.75s ease}', '.pad-left{position:fixed;width:80px;height:80px;background:#fff;border-radius:100%;margin-top:45px;margin-left:27.5px}', '.switch-right{position:fixed;background:#fff;width:185px;height:450px;border-radius:5px 100px 100px 5px;transform:translate(calc(50vw + 17px),calc(50vh - 225px));animation:switch-right-animation 1.75s ease}', '.pad-right{position:fixed;width:80px;height:80px;background:#EF5350;border-radius:100%;margin-top:225px;margin-left:50px}', '.line{width:6px;height:100vh;position:fixed;background:#fff;top:0;left:calc(50vw - 3px);opacity:.25}', '.text{font-family:logofont;font-size:80px;color:#fff;letter-spacing:19px;position:fixed;transform:translate(calc(50vw - 288px),calc(50vh + 175px))}', '.text{font-family:logofont;font-size:124px;color:#fff;letter-spacing:13px;position:fixed;transform:translate(calc(50vw - 290px),calc(50vh + 200px))}', '.text{animation: text-animation 1.75s ease;position: fixed;}', '.reload{position:fixed;width:75px;height:75px;border-radius:5px;left:calc(50vw - 37.5px);bottom:calc(50vh - 345px);cursor:pointer;transition:background 0.3s ease;animation:reload-animation 2.5s ease}', ' .logo{transform: scale(0.45);margin-top: 65px;}', 'html,body{margin:0;padding:0;width:100%;height:100%;overflow:hidden;}', 'body{margin:0;padding:0;width:100%;height:100%;overflow:hidden;}', '*{margin:0;padding:0}', '*{margin:0;padding:0;box-sizing:border-box;}', '*{box-sizing:border-box;}', '.css_lab{width:100%;height:100%;background:#224}', '.witch{width:100px;height:100px;position:absolute;top:50%;left:50%;margin:-60px;-webkit-transform:scale(3);-ms-transform:scale(3);transform:scale(3)}', 'body{background-color:#212121;color:#4db1bc;margin:0;display:grid;grid-template-columns:1fr;grid-template-rows:1fr;align-items:center;justify-items:center}', 'body img{width:100%;height:100vh;object-fit:cover;grid-column:1;grid-row:1;opacity:.7;z-index:0}', 'img{width:100%;height:100vh;object-fit:cover;grid-column:1;grid-row:1;opacity:.7;z-index:0}', \"body h1{margin:0;padding-bottom:6rem;grid-column:1;grid-row:1;z-index:1;font-family:'Teko',sans-serif;font-size:10rem;text-transform:uppercase;animation:glow 2s ease-in-out infinite alternate;text-align:center}\", \"h1{margin:0;padding-bottom:6rem;grid-column:1;grid-row:1;z-index:1;font-family:'Teko',sans-serif;font-size:10rem;text-transform:uppercase;animation:glow 2s ease-in-out infinite alternate;text-align:center}\", \"body a{font-family:'Teko',sans-serif;color:#4db1bc;grid-column:1;grid-row:1;align-self:end;justify-self:center;padding-bottom:1rem}\", \"a{font-family:'Teko',sans-serif;color:#4db1bc;grid-column:1;grid-row:1;align-self:end;justify-self:center;padding-bottom:1rem}\", '@keyframes glow{from{text-shadow:0 0 20px #2d9da9}to{text-shadow:0 0 30px #34b3c1,0 0 10px #4dbbc7}}', 'from{text-shadow:0 0 20px #2d9da9}', 'to{text-shadow:0 0 30px #34b3c1,0 0 10px #4dbbc7}', \"body{font-size:16px;color:#fff;background:#C13237;font-family:'Raleway',arial,sans-serif}\", 'h1{text-align:center;font-size:6em;font-weight:300;position:absolute;margin:0;top:50%;left:50%;-webkit-transform:translate(-50%,-50%);transform:translate(-50%,-50%)}', 'ul{padding-left:1em;position:fixed;bottom:0;font-weight:400;z-index:100;min-width:20em}', 'li{list-style:none;margin:.5em 0 0;font-size:1.75em}', 'li:hover span{opacity:1;transition:0.25s}', 'li.invisible{opacity:0;visibility:hidden;transition:all 0.25s}', 'li.animate{opacity:0;animation-duration:0.25s;animation-name:easeOutBounce;animation-fill-mode:forwards}', 'span{color:#C13237;padding:.35em;margin-left:.5em;border-radius:.2em;font-size:.75em;transition:.3s;background:#fff;opacity:0;position:relative}', \"span:before{content:'';width:0;height:0;position:absolute;left:-.4em;top:50%;margin-top:-.5em;border-style:solid;border-width:.5em .5em .5em 0;border-color:transparent #fff transparent transparent}\", 'html{--i:-1;--j:-1;--r:0;height:100%;background:url(https://images.unsplash.com/photo-1496481995273-1ba7de6c24fd?ixlib=rb-0.3.5&q=85&fm=jpg&crop=entropy&cs=srgb&ixid=eyJhcHBfaWQiOjE0NTg5fQ&s=63d82148afc0fe5a35f9752b4d511d82) 50%/cover #777;background-blend-mode:luminosity}', 'body{display:flex;flex-wrap:wrap;justify-content:center;margin:0 auto;padding-top:4em;max-width:1000px;font:1em/1.5 trebuchet ms,verdana,sans-serif}', 'header{margin:1rem;padding:1em 0;border-radius:.5em;min-width:95%;background:#fff;text-align:center}', 'article{overflow:hidden;margin:1rem;width:21em;min-width:15rem;border-radius:1em}', 'h3,section{display:flex;align-items:center;overflow:hidden;position:relative;padding:.5rem}', 'h3{display:flex;align-items:center;overflow:hidden;position:relative;padding:.5rem}', 'section{display:flex;align-items:center;overflow:hidden;position:relative;padding:.5rem}', \"h3:before{position:absolute;z-index:-1;top:calc(var(--j)*1rem + (1 + var(--j))*50% - var(--r));left:calc(var(--i)*1rem + (1 + var(--i))*50% - var(--r));padding:var(--r);border-radius:50%;box-shadow:0 0 0 50em;content:''}\", \"h3:before,section:before{position:absolute;z-index:-1;top:calc(var(--j)*1rem + (1 + var(--j))*50% - var(--r));left:calc(var(--i)*1rem + (1 + var(--i))*50% - var(--r));padding:var(--r);border-radius:50%;box-shadow:0 0 0 50em;content:''}\", \"section:before{position:absolute;z-index:-1;top:calc(var(--j)*1rem + (1 + var(--j))*50% - var(--r));left:calc(var(--i)*1rem + (1 + var(--i))*50% - var(--r));padding:var(--r);border-radius:50%;box-shadow:0 0 0 50em;content:''}\", 'h3{justify-content:center;color:#fff;font-size:1.75em;text-align:center;min-height:var(--r)}', 'section{justify-content:space-between;min-height:calc(var(--r) - 1rem)}', 'h3:before{opacity:.65}', 'section:before{color:var(--c0)}', 'p{margin-right:1em;font-size:.875em}', 'a{display:inline-block;color:inherit;text-decoration:none;text-transform:uppercase;white-space:nowrap}', 'body,html{background-image:linear-gradient(90deg,#1d1f20,#2f3031,#1d1f20);height:100%}', 'body{background-image:linear-gradient(90deg,#1d1f20,#2f3031,#1d1f20);height:100%}', 'html{background-image:linear-gradient(90deg,#1d1f20,#2f3031,#1d1f20);height:100%}', 'div.codepen{display:block;position:relative;top:50%;height:16em;width:16em;margin:-8em auto 0;border-radius:8em;background-color:#121212;cursor:pointer;transition:color 0.8s linear,background 0.8s linear,box-shadow 0.1s linear,transform 0.1s linear}', 'div{display:block;position:relative;top:50%;height:16em;width:16em;margin:-8em auto 0;border-radius:8em;background-color:#121212;cursor:pointer;transition:color 0.8s linear,background 0.8s linear,box-shadow 0.1s linear,transform 0.1s linear}', '.codepen{display:block;position:relative;top:50%;height:16em;width:16em;margin:-8em auto 0;border-radius:8em;background-color:#121212;cursor:pointer;transition:color 0.8s linear,background 0.8s linear,box-shadow 0.1s linear,transform 0.1s linear}', '*{box-sizing:border-box}', \"body{background:#222;font-family:'Gochi Hand',sans-serif;color:#333}\", 'aside.context{text-align:center;color:#fff;line-height:1.7;font-size:20px;letter-spacing:.5px}', '.context{text-align:center;color:#fff;line-height:1.7;font-size:20px;letter-spacing:.5px}', 'aside{text-align:center;color:#fff;line-height:1.7;font-size:20px;letter-spacing:.5px}', 'a{text-decoration:none;color:#fff;padding:3px 0;border-bottom:1px dashed}', 'a:hover{border-bottom:1px solid}', 'footer{text-align:center;margin:4em auto;width:100%}', 'footer a{text-decoration:none;display:inline-block;width:45px;height:45px;border-radius:50%;background:transparent;border:1px dashed #fff;color:#fff;margin:5px}', 'a{text-decoration:none;display:inline-block;width:45px;height:45px;border-radius:50%;background:transparent;border:1px dashed #fff;color:#fff;margin:5px}']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uZJoUBfwV0U"
      },
      "source": [
        "### Convertimos los datos a numeros para trabajar\n",
        "\n",
        "### Pasos a Seguir para construir mi Custom Dataset\n",
        "1.   Contruir el vocabulario para asignar a cada palabra\n",
        "2.   Configurar un dataset de Pytorch para cargar nuestro datos\n",
        "2.   Configurar el batch para que todos los ejemplos tengan las misma longitud (seq_len) y tambien configuramos el dataloader\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2zqHb7Uxw-S"
      },
      "source": [
        "## Importaciones requeridas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbu8Hq1ywabl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4f3273bf-129d-439b-a31e-eb5b797d9889"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import spacy # para la tokenizacion\n",
        "import pandas as pd # para buscar en el archivo de anotaciones (atento)\n",
        "from torch.nn.utils.rnn import pad_sequence #para el lote de almohadillas (pad batch) para que todos los datos tengan la misma longitud\n",
        "from torch.utils.data import DataLoader , Dataset #para crea el dataset y el dataloader para el entrenamiento\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda'"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clase para crear nuestro vocabulario"
      ],
      "metadata": {
        "id": "YyqCRf_NzLHX"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAyccPMCK3iu"
      },
      "source": [
        "spacy_eng = spacy.load(\"en\")\n",
        "class Vocabulary:\n",
        "\n",
        "  def __init__(self, freq_threshold):\n",
        "    self.itos = {0:\"<PAD>\", 1:\"<SOS>\", 2:\"<EOS>\", 3:\"<UNK>\"}\n",
        "    self.stoi = {\"<PAD>\":0, \"<SOS>\":1, \"<EOS>\":2, \"<UNK>\":3}\n",
        "    self.freq_threshold = freq_threshold\n",
        "\n",
        "  def __len__(self):\n",
        "    #devolvemos la longitud de nuestro vocabulario\n",
        "    return len(self.itos)\n",
        "\n",
        "  #metodo para definir el ingles de nuestro vocabulario\n",
        "  @staticmethod\n",
        "  def tokenizer_eng(text):\n",
        "    return [tok.text.lower() for tok in spacy_eng.tokenizer(text)]\n",
        "\n",
        "  #ESTO ES LO QUE HACER EJEMPLO!!!\n",
        "  # \"body{background-color:red;}\"\" => [\"body\",\"{\",\"background\",\"-\",\"color\",\":\",\"red\",\";\",\"}\"]\n",
        "\n",
        "  #construimos el vocabulario!!\n",
        "  def build_vocabulary(self, sentence_list):\n",
        "    frequencies = {}\n",
        "    idx = 4\n",
        "\n",
        "    for sentence in sentence_list:\n",
        "      for word in self.tokenizer_eng(sentence):\n",
        "        if word not in frequencies:\n",
        "          frequencies[word] = 1\n",
        "        else:\n",
        "          frequencies[word] += 1\n",
        "\n",
        "        if frequencies[word] == self.freq_threshold:\n",
        "          self.stoi[word] = idx\n",
        "          self.itos[idx] = word\n",
        "          idx += 1\n",
        "\n",
        "  def numericalize(self, text):\n",
        "    tokenized_text = self.tokenizer_eng(text)\n",
        "    return [\n",
        "            self.stoi[token] if token in self.stoi else self.stoi[\"<UNK>\"]\n",
        "            for token in tokenized_text\n",
        "    ]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-7wWWh3K4Hz"
      },
      "source": [
        "### Clase CssDataset para clasificar el conjunto de datos nuestro dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYe-StziK8MM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8b0f943-96dc-4af6-bd91-099fc67dda0a"
      },
      "source": [
        "class CssDataset(Dataset):\n",
        "\n",
        "  def __init__ (self, css_styles, freq_threshold = 5):\n",
        "    self.df = css_styles\n",
        "\n",
        "    # vamos a obtener nuestros selectores\n",
        "    self.selectors = self.df[0]\n",
        "\n",
        "    # vamos a obtener nuestros styles\n",
        "    self.styles = self.df[1]\n",
        "    \n",
        "    #Incializamos el Vocabulario (IMPORTANTEE!!!)\n",
        "    self.vocab = Vocabulary(freq_threshold)\n",
        "    self.vocab1 = Vocabulary(freq_threshold)\n",
        "\n",
        "    self.vocab.build_vocabulary(self.styles) #Pasamos las Listas a el vocabulario\n",
        "    self.vocab1.build_vocabulary(self.selectors) #Pasamos las Listas a el vocabulario\n",
        "    \n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.df[1]) #devolvemos la longitud de nuestros dataset\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    selector = self.selectors[index]\n",
        "    style = self.styles[index]\n",
        "\n",
        "    numericalized_style = [self.vocab.stoi[\"<SOS>\"]] \n",
        "    numericalized_style += self.vocab.numericalize(style) \n",
        "    numericalized_style.append(self.vocab.stoi[\"<EOS>\"]) \n",
        "\n",
        "    numericalized_selector = [self.vocab1.stoi[\"<SOS>\"]] \n",
        "    numericalized_selector += self.vocab1.numericalize(selector) \n",
        "    numericalized_selector.append(self.vocab1.stoi[\"<EOS>\"]) \n",
        "\n",
        "    return torch.tensor(numericalized_selector) , torch.tensor(numericalized_style) \n",
        "\n",
        "\n",
        "train = CssDataset(data_css)\n",
        "# len(train)\n",
        "# print(type(train))\n",
        "print(train.selectors[0])\n",
        "print(train.selectors[5])\n",
        "print(train.styles[0])\n",
        "print(train.styles[5])\n",
        "print(train.__getitem__(0))\n",
        "print(train.__getitem__(5))\n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "body\n",
            "body\n",
            "body{overflow:hidden;background:rgb(25,35,125)}\n",
            "body {margin: 0px;background: #EF5350;}\n",
            "(tensor([1, 5, 2]), tensor([1, 3, 4, 3, 4, 3, 7, 6, 2]))\n",
            "(tensor([1, 5, 2]), tensor([ 1, 26, 10,  3,  4,  3,  4, 14,  3,  9,  6,  2]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clase para cargar los datos"
      ],
      "metadata": {
        "id": "SqLMlAamBvzl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyCollate:\n",
        "\n",
        "  def __init__(self, pad_idx):\n",
        "    self.pad_idx = pad_idx\n",
        "\n",
        "  def __call__(self, batch):\n",
        "    targets = [item[0] for item in batch]\n",
        "    targets = pad_sequence(targets, batch_first = False, padding_value = self.pad_idx )\n",
        "\n",
        "    targets1 = [item[1] for item in batch]\n",
        "    targets1 = pad_sequence(targets1, batch_first = False, padding_value = self.pad_idx )\n",
        "\n",
        "    return targets, targets1\n",
        "\n",
        "def get_loader(css_styles, batch_size = 32, num_workers = 8, shuffle = True, pin_memory = True):\n",
        "  dataset = CssDataset(css_styles)\n",
        "  pad_idx = dataset.vocab.stoi[\"<PAD>\"]\n",
        "\n",
        "  dataloader = DataLoader(\n",
        "      dataset = dataset,\n",
        "      batch_size = batch_size,\n",
        "      num_workers = num_workers,\n",
        "      shuffle= shuffle,\n",
        "      pin_memory=pin_memory,\n",
        "      collate_fn=MyCollate(pad_idx=pad_idx),\n",
        "  )\n",
        "\n",
        "  return dataset, dataloader\n",
        "\n",
        "def main():\n",
        "  dataset, dataloader = get_loader(data_css)\n",
        "  print(dataloader)\n",
        "  print(dataset)\n",
        "  for idx , (selectors, styles) in enumerate(dataloader):\n",
        "    # print(selectors.shape)\n",
        "    # print(styles.shape)\n",
        "    print(selectors)\n",
        "    print(styles)\n",
        "    # print(type(selectors))\n",
        "    # print(type(styles))\n",
        "    # print(idx)\n",
        "\n",
        "if __name__ == \"__main__\" :\n",
        "  main()\n",
        "\n"
      ],
      "metadata": {
        "id": "HZhlq6IcBhhO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd780f49-1194-4781-fadb-46a6e06d0b56"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<torch.utils.data.dataloader.DataLoader object at 0x7f30309d0050>\n",
            "<__main__.CssDataset object at 0x7f30309b9890>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
            "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
            "        [ 3,  5,  8, 10,  3,  3,  3,  5,  3,  5,  3,  3,  3,  3,  3,  3,  3,  3,\n",
            "          9,  9,  3,  3,  3,  3,  3,  8,  5,  3,  3, 10,  3,  3],\n",
            "        [ 2,  2,  6,  6,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  4,  2,  2,  2,\n",
            "          6,  6,  2,  2,  2,  2,  3,  2,  3,  2,  2,  2,  4,  6],\n",
            "        [ 0,  0,  7,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  3,  0,  0,  0,\n",
            "          7,  7,  0,  0,  0,  0,  5,  0,  2,  0,  0,  0,  3,  3],\n",
            "        [ 0,  0,  3,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  2,  0,  0,  0,\n",
            "          2,  2,  0,  0,  0,  0,  2,  0,  0,  0,  0,  0,  2,  3],\n",
            "        [ 0,  0,  9,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  2],\n",
            "        [ 0,  0,  6,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "        [ 0,  0,  7,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "        [ 0,  0,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])\n",
            "tensor([[ 1,  1,  1,  ...,  1,  1,  1],\n",
            "        [ 3,  3,  3,  ...,  3,  3,  3],\n",
            "        [ 5,  5,  4,  ...,  5,  5,  4],\n",
            "        ...,\n",
            "        [ 0,  0, 25,  ...,  0,  0,  0],\n",
            "        [ 0,  0,  6,  ...,  0,  0,  0],\n",
            "        [ 0,  0,  2,  ...,  0,  0,  0]])\n",
            "tensor([[ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
            "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
            "        [ 3,  3, 10,  3,  3,  3,  8,  5,  3,  3,  3,  3,  3,  3,  3,  5,  3,  5,\n",
            "          3,  3,  8, 10,  3,  3,  9,  3,  3,  3,  5,  3,  3,  3],\n",
            "        [ 2,  4,  2,  2,  2,  2,  2, 10,  2,  2,  2,  2,  2,  2, 10,  2,  2,  2,\n",
            "          2,  2,  6,  2,  2,  3,  2,  2,  2,  4,  3,  2,  2,  2],\n",
            "        [ 0,  3,  0,  0,  0,  0,  0,  2,  0,  0,  0,  0,  0,  0,  2,  0,  0,  0,\n",
            "          0,  0,  7,  0,  0,  2,  0,  0,  0,  3,  3,  0,  0,  0],\n",
            "        [ 0,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0,  2,  0,  0,  0,  0,  0,  0,  2,  2,  0,  0,  0]])\n",
            "tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
            "        [3, 3, 3,  ..., 3, 3, 3],\n",
            "        [5, 5, 5,  ..., 4, 5, 4],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 2, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]])\n",
            "tensor([[ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
            "        [ 5,  9,  3,  3,  3,  8,  5,  3,  5,  5, 10],\n",
            "        [ 2,  2,  6,  4,  4,  6,  3,  2,  2,  2,  2],\n",
            "        [ 0,  0,  7,  3,  3,  7,  2,  0,  0,  0,  0],\n",
            "        [ 0,  0,  2,  2,  2,  2,  0,  0,  0,  0,  0]])\n",
            "tensor([[ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
            "        [ 3,  3,  3,  3,  3,  3, 26,  3, 26,  3,  3],\n",
            "        [ 4,  4,  4,  5,  5,  4,  3,  5, 10,  5,  4],\n",
            "        [ 3,  3,  3,  3,  3,  3,  5,  3,  3,  3,  3],\n",
            "        [ 4,  5,  4,  4,  4,  4,  3,  4,  4,  4,  5],\n",
            "        [ 3, 18,  3,  3,  3,  3,  4,  3,  3,  3,  3],\n",
            "        [ 7,  4,  5,  5,  4,  5,  3,  5,  4,  5,  4],\n",
            "        [ 6,  3,  3,  3,  3,  3,  5,  3, 14,  3,  3],\n",
            "        [ 2,  4,  5,  5,  5,  4, 13,  5,  3,  5,  5],\n",
            "        [ 0,  3,  3,  3,  3,  3,  5,  3,  9,  3,  3],\n",
            "        [ 0,  4,  4,  5,  3, 19,  3,  4,  6,  5,  4],\n",
            "        [ 0,  3,  3,  3,  3, 23,  5,  3,  2,  3,  3],\n",
            "        [ 0,  6,  5,  6,  3, 24,  3,  4,  0,  5,  5],\n",
            "        [ 0,  2,  3,  2,  3, 19,  6,  3,  0,  3, 11],\n",
            "        [ 0,  0,  3,  0, 14,  3,  2,  5,  0,  5,  4],\n",
            "        [ 0,  0,  3,  0,  3, 20,  0,  3,  0, 18,  3],\n",
            "        [ 0,  0, 29,  0,  4,  5,  0, 19,  0,  4,  5],\n",
            "        [ 0,  0,  5,  0,  3,  3,  0,  3,  0,  3,  3],\n",
            "        [ 0,  0,  3,  0,  5,  4,  0,  7,  0,  5,  4],\n",
            "        [ 0,  0,  4,  0,  3,  3,  0,  7,  0, 18,  3],\n",
            "        [ 0,  0,  3,  0,  5, 19,  0,  6,  0,  4,  6],\n",
            "        [ 0,  0, 14,  0,  3, 23,  0,  2,  0,  3,  2],\n",
            "        [ 0,  0,  3,  0,  4, 24,  0,  0,  0,  6,  0],\n",
            "        [ 0,  0,  3,  0,  3, 19,  0,  0,  0,  2,  0],\n",
            "        [ 0,  0,  3,  0,  5,  3,  0,  0,  0,  0,  0],\n",
            "        [ 0,  0,  6,  0,  3, 20,  0,  0,  0,  0,  0],\n",
            "        [ 0,  0,  2,  0,  5,  5,  0,  0,  0,  0,  0],\n",
            "        [ 0,  0,  0,  0,  8,  3,  0,  0,  0,  0,  0],\n",
            "        [ 0,  0,  0,  0,  3,  4,  0,  0,  0,  0,  0],\n",
            "        [ 0,  0,  0,  0, 12,  3,  0,  0,  0,  0,  0],\n",
            "        [ 0,  0,  0,  0,  6,  5,  0,  0,  0,  0,  0],\n",
            "        [ 0,  0,  0,  0,  2,  3,  0,  0,  0,  0,  0],\n",
            "        [ 0,  0,  0,  0,  0,  5,  0,  0,  0,  0,  0],\n",
            "        [ 0,  0,  0,  0,  0, 21,  0,  0,  0,  0,  0],\n",
            "        [ 0,  0,  0,  0,  0, 15,  0,  0,  0,  0,  0],\n",
            "        [ 0,  0,  0,  0,  0, 15,  0,  0,  0,  0,  0],\n",
            "        [ 0,  0,  0,  0,  0,  3,  0,  0,  0,  0,  0],\n",
            "        [ 0,  0,  0,  0,  0,  4,  0,  0,  0,  0,  0],\n",
            "        [ 0,  0,  0,  0,  0, 25,  0,  0,  0,  0,  0],\n",
            "        [ 0,  0,  0,  0,  0, 25,  0,  0,  0,  0,  0],\n",
            "        [ 0,  0,  0,  0,  0,  6,  0,  0,  0,  0,  0],\n",
            "        [ 0,  0,  0,  0,  0,  2,  0,  0,  0,  0,  0]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-11:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/pin_memory.py\", line 28, in _pin_memory_loop\n",
            "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 113, in get\n",
            "    return _ForkingPickler.loads(res)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/multiprocessing/reductions.py\", line 289, in rebuild_storage_fd\n",
            "    fd = df.detach()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/resource_sharer.py\", line 57, in detach\n",
            "    with _resource_sharer.get_connection(self._id) as conn:\n",
            "  File \"/usr/lib/python3.7/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
            "    c = Client(address, authkey=process.current_process().authkey)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 492, in Client\n",
            "    c = SocketClient(address)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 620, in SocketClient\n",
            "    s.connect(address)\n",
            "FileNotFoundError: [Errno 2] No such file or directory\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Usaremos Perceptr√≥n Multicapa (MLP) para el Generador y Discriminador"
      ],
      "metadata": {
        "id": "uY9wXuXeJgFT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CharRNN(torch.nn.Module):\n",
        "  def __init__(self, input_size, embedding_size=128, hidden_size=256, num_layers=2, dropout=0.2):\n",
        "    super().__init__()\n",
        "    self.encoder = torch.nn.Embedding(input_size, embedding_size)\n",
        "    self.rnn = torch.nn.LSTM(input_size=embedding_size, hidden_size=hidden_size, num_layers=num_layers, dropout=dropout, batch_first=True)\n",
        "    self.fc = torch.nn.Linear(hidden_size, input_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.encoder(x)\n",
        "    x, h = self.rnn(x)         \n",
        "    y = self.fc(x[:,-1,:])\n",
        "    return y"
      ],
      "metadata": {
        "id": "2aSp8BfEJnVD"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CharRNN(input_size=114)\n",
        "outputs = model(torch.randint(0, 114, (64, 50)))\n",
        "outputs.shape"
      ],
      "metadata": {
        "id": "pa24rCygeEf1",
        "outputId": "9b387f7d-310f-47ab-b0c8-4cccc9a3a9bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 114])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "def fit(model, dataloader, epochs=10):\n",
        "    model.to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    for epoch in range(1, epochs+1):\n",
        "        model.train()\n",
        "        train_loss = []\n",
        "        bar = tqdm(dataloader)\n",
        "        for batch in bar:\n",
        "            X, y = batch\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            y_hat = model(X)\n",
        "            loss = criterion(y_hat, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss.append(loss.item())\n",
        "            bar.set_description(f\"loss {np.mean(train_loss):.5f}\")\n",
        "        bar = tqdm(dataloader)\n",
        "        val_loss = []\n",
        "        with torch.no_grad():\n",
        "            for batch in bar:\n",
        "                X, y = batch\n",
        "                X, y = X.to(device), y.to(device)\n",
        "                y_hat = model(X)\n",
        "                loss = criterion(y_hat, y)\n",
        "                val_loss.append(loss.item())\n",
        "                bar.set_description(f\"val_loss {np.mean(val_loss):.5f}\")\n",
        "        print(f\"Epoch {epoch}/{epochs} loss {np.mean(train_loss):.5f} val_loss {np.mean(val_loss):.5f}\")\n",
        "\n",
        "def predict(model, X):\n",
        "    model.eval() \n",
        "    with torch.no_grad():\n",
        "        X = torch.tensor(X).to(device)\n",
        "        pred = model(X.unsqueeze(0))\n",
        "        return pred"
      ],
      "metadata": {
        "id": "K3i7o5Bvfu-K"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset, dataloader = get_loader(data_css)\n",
        "print(len(dataloader))\n",
        "print(type(dataloader))\n",
        "i , ss , sss = dataloader\n",
        "\n",
        "# print(sss)\n",
        "model = CharRNN(input_size=114)\n",
        "fit(model, dataloader, epochs=20)"
      ],
      "metadata": {
        "id": "nhPSQ0dof2rx",
        "outputId": "d3f79bfa-50a9-4544-af16-8885093b7a8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "<class 'torch.utils.data.dataloader.DataLoader'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-2cbfeca390f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mi\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mss\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0msss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# print(sss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1143\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}